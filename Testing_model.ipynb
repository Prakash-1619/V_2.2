{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "XJ4CzJUZ6uc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Base Directory:\n",
      " C:\\Users\\pooja\\Downloads\\FLIPOSE_DATA\\V_2.2\\Models_predictions\n",
      "\n",
      "Files in directory: ['.ipynb_checkpoints', 'forecast_df.csv', 'historic_df.csv', 'Models', 'Models_predictions.zip', 'predict_price.py', 'price_api', 'Testing_model.ipynb', 'testing_model.py', 'Trained Columns', 'V_2.2_inputs.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. BASE DIRECTORY\n",
    "# ============================================================\n",
    "\n",
    "BASE_DIR = os.path.join(\n",
    "    os.path.expanduser(\"~\"),\n",
    "    \"Downloads\",\n",
    "    \"FLIPOSE_DATA\",\n",
    "    \"V_2.2\",\n",
    "    \"Models_predictions\"\n",
    ")\n",
    "\n",
    "print(\"Using Base Directory:\\n\", BASE_DIR)\n",
    "print(\"\\nFiles in directory:\", os.listdir(BASE_DIR))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. DIRECT MODEL AREAS (NO MAPPING)\n",
    "# ============================================================\n",
    "\n",
    "DIRECT_MODEL_AREAS = {\n",
    "    \"Al Barsha South Fourth\",\n",
    "    \"Business Bay\",\n",
    "    \"Al Merkadh\",\n",
    "    \"Burj Khalifa\",\n",
    "    \"Hadaeq Sheikh Mohammed Bin Rashid\",\n",
    "    \"Al Khairan First\",\n",
    "    \"Wadi Al Safa 5\",\n",
    "    \"Al Thanyah Fifth\",\n",
    "    \"Al Barshaa South Third\",\n",
    "    \"Jabal Ali First\",\n",
    "    \"Madinat Al Mataar\",\n",
    "    \"Madinat Dubai Almelaheyah\",\n",
    "    \"Me'Aisem First\",\n",
    "    \"Al Hebiah Fourth\",\n",
    "    \"Al Barsha South Fifth\",\n",
    "    \"Al Hebiah First\",\n",
    "    \"Nadd Hessa\",\n",
    "    \"Palm Jumeirah\",\n",
    "    \"Al Barshaa South Second\",\n",
    "    \"Al Yelayiss 2\",\n",
    "    \"Al Warsan First\"\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. PROXY / GROUP MAPPING\n",
    "# ============================================================\n",
    "\n",
    "PROXY_MAPPING = {\n",
    "\n",
    "    # proxy1\n",
    "    \"Al Barsha First\": \"proxy1\",\n",
    "    \"Al Barshaa South Second\": \"proxy1\",\n",
    "    \"Al Hebiah Second\": \"proxy1\",\n",
    "    \"Al Hebiah Sixth\": \"proxy1\",\n",
    "    \"Al Hebiah Third\": \"proxy1\",\n",
    "    \"Madinat Hind 4\": \"proxy1\",\n",
    "    \"Wadi Al Safa 3\": \"proxy1\",\n",
    "    \"Wadi Al Safa 4\": \"proxy1\",\n",
    "    \"Wadi Al Safa 7\": \"proxy1\",\n",
    "\n",
    "    # proxy2\n",
    "    \"Bukadra\": \"proxy2\",\n",
    "    \"Hadaeq Sheikh Mohammed Bin Rashid\": \"proxy2\",\n",
    "    \"Ras Al Khor Industrial First\": \"proxy2\",\n",
    "    \"Jumeirah First\": \"proxy2\",\n",
    "    \"Palm Deira\": \"proxy2\",\n",
    "    \"Al Khairan First\": \"proxy2\",\n",
    "\n",
    "    # proxy3\n",
    "    \"Al Thanyah Third\": \"proxy3\",\n",
    "    \"Jabal Ali Industrial Second\": \"proxy3\",\n",
    "\n",
    "    # groups\n",
    "    \"Al Kifaf\": \"G1\",\n",
    "    \"Warsan Fourth\": \"G3\",\n",
    "    \"Jabal Ali\": \"G3\",\n",
    "    \"Zaabeel Second\": \"G4\",\n",
    "    \"Zaabeel First\": \"G4\"\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. LOAD TRAIN COLUMNS\n",
    "# ===========================================================\n",
    "COL_DIR = os.path.join(BASE_DIR,\n",
    "\"Trained Columns\"\n",
    ")\n",
    "def load_columns(model_key):\n",
    "    for f in os.listdir(COL_DIR):\n",
    "        if f.lower() == f\"trained_columns_{model_key}.pkl\".lower():\n",
    "            with open(os.path.join(COL_DIR, f), \"rb\") as file:\n",
    "                return pickle.load(file)\n",
    "\n",
    "    raise FileNotFoundError(f\"trained_columns_{model_key}.pkl not found\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. LOAD MODEL\n",
    "# ============================================================\n",
    "\n",
    "MODEL_DIR = os.path.join(BASE_DIR,\n",
    "\"Models\"\n",
    ")\n",
    "def load_model(model_key):\n",
    "    for f in os.listdir(MODEL_DIR):\n",
    "        if f.lower() == f\"rf_model_{model_key}.pkl\".lower():\n",
    "            with open(os.path.join(MODEL_DIR, f), \"rb\") as file:\n",
    "                return pickle.load(file)\n",
    "\n",
    "    raise FileNotFoundError(f\"rf_model_{model_key}.pkl not found\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. MAIN PREDICTION FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def predict_with_proxy(input_data, forecast_df, historic_df):\n",
    "\n",
    "    area = input_data[\"area_name\"]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Decide model key\n",
    "    # --------------------------------------------------------\n",
    "    if area in DIRECT_MODEL_AREAS:\n",
    "        model_key = area\n",
    "        model_type = \"direct\"\n",
    "    elif area in PROXY_MAPPING:\n",
    "        model_key = PROXY_MAPPING[area]\n",
    "        model_type = \"proxy\"\n",
    "    else:\n",
    "        raise ValueError(f\"No model found for area: {area}\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Load model & columns\n",
    "    # --------------------------------------------------------\n",
    "    train_columns = load_columns(model_key)\n",
    "    model = load_model(model_key)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Feature engineering\n",
    "    # --------------------------------------------------------\n",
    "    categorical_features = [\n",
    "        \"reg_type_en\",\n",
    "        \"rooms_en\",\n",
    "        \"land_type_en\",\n",
    "        \"floor_bin\",\n",
    "        \"developer_cat\",\n",
    "        \"project_cat\"\n",
    "    ]\n",
    "\n",
    "    binary_features = [\n",
    "        \"has_parking\",\n",
    "        \"swimming_pool\",\n",
    "        \"balcony\",\n",
    "        \"elevator\",\n",
    "        \"metro\"\n",
    "    ]\n",
    "\n",
    "    continuous_features = [\"procedure_area\"]\n",
    "\n",
    "    temp = pd.DataFrame([input_data])\n",
    "    temp = temp[categorical_features + binary_features + continuous_features]\n",
    "\n",
    "    temp = pd.get_dummies(temp, columns=categorical_features, drop_first=False)\n",
    "\n",
    "    for col in train_columns:\n",
    "        if col not in temp.columns:\n",
    "            temp[col] = 0\n",
    "\n",
    "    temp = temp[train_columns]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Predict\n",
    "    # --------------------------------------------------------\n",
    "    predicted_price = model.predict(temp)[0]\n",
    "    print(\"Raw Model Prediction:\", predicted_price)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # DIRECT MODEL → RETURN ONLY PREDICTION\n",
    "    # --------------------------------------------------------\n",
    "    # --------------------------------------------------------\n",
    "    # APPLY FORECAST & HISTORIC IF DATA EXISTS\n",
    "    # --------------------------------------------------------\n",
    "    \n",
    "    has_forecast = model_key in forecast_df[\"area\"].values\n",
    "    has_historic = model_key in historic_df[\"area\"].values\n",
    "    \n",
    "    # If no time-series data → return simple prediction\n",
    "    if not has_forecast and not has_historic:\n",
    "        return pd.DataFrame({\n",
    "            \"area\": [area],\n",
    "            \"predicted_price\": [predicted_price]\n",
    "        })\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # FORECAST DATA\n",
    "    # --------------------------------------------------------\n",
    "    gf = forecast_df[forecast_df[\"area\"] == model_key].copy()\n",
    "    \n",
    "    if not gf.empty:\n",
    "        gf[\"median_price\"] = predicted_price * gf[\"growth_factor\"]\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # HISTORIC DATA\n",
    "    # --------------------------------------------------------\n",
    "    historic = historic_df[historic_df[\"area\"] == model_key].copy()\n",
    "    \n",
    "    if not historic.empty:\n",
    "        historic.loc[historic.index[-1], \"median_price\"] = predicted_price\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # FINAL TIME SERIES\n",
    "    # --------------------------------------------------------\n",
    "    final_df = pd.concat([historic, gf], ignore_index=True)\n",
    "    \n",
    "    final_df = final_df[[\"month\", \"median_price\", \"area\"]]\n",
    "    final_df[\"area\"] = area  # show requested area name\n",
    "    final_df[\"month\"] = pd.to_datetime(final_df[\"month\"], format=\"%d-%m-%Y\")\n",
    "    \n",
    "    final_df = (\n",
    "        final_df\n",
    "        .sort_values(\"month\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    return final_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mAPYYvc7AnZ"
   },
   "source": [
    "    # --------------------------------------------------------\n",
    "    # Step 3: One-hot encode input\n",
    "    # --------------------------------------------------------\n",
    "    temp = pd.DataFrame([input_data])\n",
    "    temp = pd.get_dummies(temp)\n",
    "\n",
    "    # Add missing columns\n",
    "    for col in train_columns:\n",
    "        if col not in temp.columns:\n",
    "            temp[col] = 0\n",
    "\n",
    "    # Align strictly with model columns\n",
    "    temp = temp[train_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "a5rafrcq64vE"
   },
   "outputs": [],
   "source": [
    "forecast_df = pd.read_csv(\"forecast_df.csv\")\n",
    "historic_df = pd.read_csv(\"historic_df.csv\")\n",
    "\n",
    "DIRECT_MODEL_AREAS = {\n",
    "    \"Al Barsha South Fourth\",\n",
    "    \"Business Bay\",\n",
    "    \"Al Merkadh\",\n",
    "    \"Burj Khalifa\",\n",
    "    \"Hadaeq Sheikh Mohammed Bin Rashid\",\n",
    "    \"Al Khairan First\",\n",
    "    \"Wadi Al Safa 5\",\n",
    "    \"Al Thanyah Fifth\",\n",
    "    \"Al Barshaa South Third\",\n",
    "    \"Jabal Ali First\",\n",
    "    \"Madinat Al Mataar\",\n",
    "    \"Madinat Dubai Almelaheyah\",\n",
    "    \"Me'Aisem First\",\n",
    "    \"Al Hebiah Fourth\",\n",
    "    \"Al Barsha South Fifth\",\n",
    "    \"Al Hebiah First\",\n",
    "    \"Nadd Hessa\",\n",
    "    \"Palm Jumeirah\",\n",
    "    \"Al Barshaa South Second\",\n",
    "    \"Al Yelayiss 2\",\n",
    "    \"Al Warsan First\"\n",
    "}\n",
    "\n",
    "\n",
    "proxy_mapping = {\n",
    "\n",
    "    # =====================================================\n",
    "    # INPUT AREAS → PROXY 1\n",
    "    # =====================================================\n",
    "    \"Al Barsha First\": \"proxy1\",\n",
    "    \"Al Barshaa South Second\": \"proxy1\",\n",
    "    \"Al Hebiah Second\": \"proxy1\",\n",
    "    \"Al Hebiah Sixth\": \"proxy1\",\n",
    "    \"Al Hebiah Third\": \"proxy1\",\n",
    "    \"Madinat Hind 4\": \"proxy1\",\n",
    "    \"Wadi Al Safa 3\": \"proxy1\",\n",
    "    \"Wadi Al Safa 4\": \"proxy1\",\n",
    "    \"Wadi Al Safa 7\": \"proxy1\",\n",
    "\n",
    "    # =====================================================\n",
    "    # INPUT AREAS → PROXY 2\n",
    "    # =====================================================\n",
    "    \"Bukadra\": \"proxy2\",\n",
    "    \"Hadaeq Sheikh Mohammed Bin Rashid\": \"proxy2\",\n",
    "    \"Ras Al Khor Industrial First\": \"proxy2\",\n",
    "    \"Jumeirah First\": \"proxy2\",\n",
    "    \"Palm Deira\": \"proxy2\",\n",
    "    \"Al Khairan First\": \"proxy2\",\n",
    "\n",
    "    # =====================================================\n",
    "    # INPUT AREAS → PROXY 3\n",
    "    # =====================================================\n",
    "    \"Al Thanyah Third\": \"proxy3\",\n",
    "    \"Jabal Ali Industrial Second\": \"proxy3\",\n",
    "\n",
    "    # =====================================================\n",
    "    # INPUT AREAS → G1\n",
    "    # =====================================================\n",
    "    \"Al Kifaf\": \"G1\",\n",
    "\n",
    "    # =====================================================\n",
    "    # INPUT AREAS → G3\n",
    "    # =====================================================\n",
    "    \"Warsan Fourth\": \"G3\",\n",
    "    \"Jabal Ali\": \"G3\",\n",
    "\n",
    "    # =====================================================\n",
    "    # INPUT AREAS → G4\n",
    "    # =====================================================\n",
    "    \"Zaabeel Second\": \"G4\",\n",
    "    \"Zaabeel First\": \"G4\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "2S5iYcRC67WO"
   },
   "outputs": [],
   "source": [
    "input_data = {\n",
    "    \"area_name\": \"Al Hebiah First\",\n",
    "\n",
    "    # categorical\n",
    "    \"reg_type_en\": \"off-plan\",\n",
    "    \"rooms_en\": \"1B/R\",\n",
    "    \"land_type_en\": \"Commercial\",\n",
    "    \"floor_bin\": \"11-20\",\n",
    "    \"developer_cat\": \"Grade 2\",\n",
    "    \"project_cat\": \"Mid_Rise\",\n",
    "\n",
    "    # binary\n",
    "    \"has_parking\": 1,\n",
    "    \"swimming_pool\": 0,\n",
    "    \"balcony\": 0,\n",
    "    \"elevator\": 1,\n",
    "    \"metro\": 1,\n",
    "\n",
    "    # continuous\n",
    "    \"procedure_area\": 20\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "1byzWq9W7i1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Model Prediction: 13756.993107286125\n",
      "\n",
      "FINAL DF:\n",
      "         month  median_price             area\n",
      "67 2025-08-01  15195.730000  Al Hebiah First\n",
      "68 2025-09-01  15894.080000  Al Hebiah First\n",
      "69 2025-10-01  13756.993107  Al Hebiah First\n",
      "70 2025-12-01  13665.902804  Al Hebiah First\n",
      "71 2025-12-01  13718.178577  Al Hebiah First\n",
      "72 2026-01-01  13985.164091  Al Hebiah First\n",
      "73 2026-01-01  13584.976507  Al Hebiah First\n",
      "74 2026-02-01  13427.018978  Al Hebiah First\n",
      "75 2026-02-01  14254.425631  Al Hebiah First\n",
      "76 2026-03-01  14258.842548  Al Hebiah First\n",
      "77 2026-03-01  13288.836295  Al Hebiah First\n",
      "78 2026-04-01  13301.649201  Al Hebiah First\n",
      "79 2026-04-01  14257.831959  Al Hebiah First\n",
      "80 2026-05-01  13468.491972  Al Hebiah First\n",
      "81 2026-05-01  14391.398440  Al Hebiah First\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.8.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\pooja\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.8.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "final_output = predict_with_proxy(\n",
    "    input_data,\n",
    "    forecast_df,\n",
    "    historic_df\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL DF:\\n\", final_output.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
